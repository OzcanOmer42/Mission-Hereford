{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "995c973f-f51b-4c70-ac28-a399d53fba97",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kaggle_evaluation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpolars\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkaggle_evaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjane_street_inference_server\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeSeriesSplit, GridSearchCV\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kaggle_evaluation'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import kaggle_evaluation.jane_street_inference_server\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "lags_ = None\n",
    "rf_model = None\n",
    "feature_columns = [f\"feature_{i:02d}\" for i in range(79)]\n",
    "median_values = None\n",
    "symbol_encoder = None\n",
    "\n",
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    global lags_, rf_model, median_values, symbol_encoder\n",
    "\n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "\n",
    "    if rf_model is None:\n",
    "        train_path = \"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet\"\n",
    "        lags_path = \"/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet\"\n",
    "\n",
    "        train_df = pd.read_parquet(train_path)\n",
    "        lags_df = pd.read_parquet(lags_path)\n",
    "\n",
    "        train_df = train_df.merge(lags_df, on=[\"symbol_id\", \"date_id\"], how=\"left\")\n",
    "\n",
    "        target_col = \"responder_6\"\n",
    "        lag_columns = [col for col in lags_df.columns if col not in ['symbol_id', 'date_id']]\n",
    "        all_feature_columns = feature_columns + lag_columns\n",
    "\n",
    "        train_df = train_df.dropna(subset=[target_col])\n",
    "\n",
    "        symbol_encoder = LabelEncoder()\n",
    "        train_df['symbol_id_encoded'] = symbol_encoder.fit_transform(train_df['symbol_id'])\n",
    "        all_feature_columns += ['symbol_id_encoded']\n",
    "\n",
    "        train_df['date_id_sin'] = np.sin(2 * np.pi * train_df['date_id'] / 365)\n",
    "        train_df['date_id_cos'] = np.cos(2 * np.pi * train_df['date_id'] / 365)\n",
    "        all_feature_columns += ['date_id_sin', 'date_id_cos']\n",
    "\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        train_df[all_feature_columns] = imputer.fit_transform(train_df[all_feature_columns])\n",
    "\n",
    "        X = train_df[all_feature_columns]\n",
    "        y = train_df[target_col]\n",
    "\n",
    "        tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [10, 20],\n",
    "            'min_samples_leaf': [1, 2],\n",
    "            'max_features': ['auto', 'sqrt']\n",
    "        }\n",
    "\n",
    "        rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=rf,\n",
    "            param_grid=param_grid,\n",
    "            cv=tscv,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        grid_search.fit(X, y)\n",
    "\n",
    "        rf_model = grid_search.best_estimator_\n",
    "\n",
    "    test_df = test.to_pandas()\n",
    "\n",
    "    if lags_ is not None:\n",
    "        test_lags_df = lags_.to_pandas()\n",
    "        test_df = test_df.merge(test_lags_df, on=[\"symbol_id\", \"date_id\"], how=\"left\")\n",
    "    else:\n",
    "        for lag_col in lag_columns:\n",
    "            test_df[lag_col] = 0\n",
    "\n",
    "    test_df['symbol_id_encoded'] = symbol_encoder.transform(\n",
    "        test_df['symbol_id'].fillna('unknown')\n",
    "    )\n",
    "\n",
    "    test_df['date_id_sin'] = np.sin(2 * np.pi * test_df['date_id'] / 365)\n",
    "    test_df['date_id_cos'] = np.cos(2 * np.pi * test_df['date_id'] / 365)\n",
    "\n",
    "    test_features = test_df[all_feature_columns]\n",
    "\n",
    "    test_features = test_features.fillna(train_df[all_feature_columns].median())\n",
    "\n",
    "    test_df[\"responder_6\"] = rf_model.predict(test_features)\n",
    "\n",
    "    predictions = pl.DataFrame({\n",
    "        \"row_id\": test_df[\"row_id\"],\n",
    "        \"responder_6\": test_df[\"responder_6\"]\n",
    "    })\n",
    "\n",
    "    return predictions\n",
    "    \n",
    "inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n",
    "            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d11cb-b4ad-45e0-b80e-fdefc1610de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3723eca-1b4e-4f7d-90b4-e9bee40596bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}





import os
import numpy as np
import pandas as pd
import polars as pl
import kaggle_evaluation.jane_street_inference_server

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer

import pyarrow.parquet as pq  # Import PyArrow for chunked reading

lags_ = None
rf_model = None
feature_columns = [f"feature_{i:02d}" for i in range(79)]
median_values = None
symbol_encoder = None

# Function to read Parquet files in chunks
def read_parquet_in_chunks(parquet_path):
    parquet_file = pq.ParquetFile(parquet_path)
    num_row_groups = parquet_file.num_row_groups
    for i in range(num_row_groups):
        table = parquet_file.read_row_group(i)
        df = table.to_pandas()
        yield df

def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:
    global lags_, rf_model, median_values, symbol_encoder, all_feature_columns, lag_columns, train_df

    if lags is not None:
        lags_ = lags

    if rf_model is None:
        train_path = "/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet"
        lags_path = "/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet"

        # Read lags_df in chunks and concatenate
        lags_df_list = []
        for chunk in read_parquet_in_chunks(lags_path):
            lags_df_list.append(chunk)
        lags_df = pd.concat(lags_df_list, ignore_index=True)

        # Read train_df in chunks and merge with lags_df
        train_df_list = []
        for chunk in read_parquet_in_chunks(train_path):
            chunk = chunk.merge(lags_df, on=["symbol_id", "date_id"], how="left")
            train_df_list.append(chunk)
        train_df = pd.concat(train_df_list, ignore_index=True)

        target_col = "responder_6"
        lag_columns = [col for col in lags_df.columns if col not in ['symbol_id', 'date_id']]
        all_feature_columns = feature_columns + lag_columns

        train_df = train_df.dropna(subset=[target_col])

        symbol_encoder = LabelEncoder()
        train_df['symbol_id_encoded'] = symbol_encoder.fit_transform(train_df['symbol_id'])
        all_feature_columns += ['symbol_id_encoded']

        train_df['date_id_sin'] = np.sin(2 * np.pi * train_df['date_id'] / 365)
        train_df['date_id_cos'] = np.cos(2 * np.pi * train_df['date_id'] / 365)
        all_feature_columns += ['date_id_sin', 'date_id_cos']

        imputer = SimpleImputer(strategy='median')
        train_df[all_feature_columns] = imputer.fit_transform(train_df[all_feature_columns])

        X = train_df[all_feature_columns]
        y = train_df[target_col]

        tscv = TimeSeriesSplit(n_splits=5)

        param_grid = {
            'n_estimators': [100, 200],
            'max_depth': [10, 20],
            'min_samples_leaf': [1, 2],
            'max_features': ['auto', 'sqrt']
        }

        rf = RandomForestRegressor(random_state=42, n_jobs=-1)

        grid_search = GridSearchCV(
            estimator=rf,
            param_grid=param_grid,
            cv=tscv,
            scoring='neg_mean_squared_error',
            verbose=1
        )

        grid_search.fit(X, y)

        rf_model = grid_search.best_estimator_

    test_df = test.to_pandas()

    if lags_ is not None:
        test_lags_df = lags_.to_pandas()
        test_df = test_df.merge(test_lags_df, on=["symbol_id", "date_id"], how="left")
    else:
        for lag_col in lag_columns:
            test_df[lag_col] = 0

    test_df['symbol_id_encoded'] = symbol_encoder.transform(
        test_df['symbol_id'].fillna('unknown')
    )

    test_df['date_id_sin'] = np.sin(2 * np.pi * test_df['date_id'] / 365)
    test_df['date_id_cos'] = np.cos(2 * np.pi * test_df['date_id'] / 365)

    test_features = test_df[all_feature_columns]

    test_features = test_features.fillna(train_df[all_feature_columns].median())

    test_df["responder_6"] = rf_model.predict(test_features)

    predictions = pl.DataFrame({
        "row_id": test_df["row_id"],
        "responder_6": test_df["responder_6"]
    })

    return predictions

inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)

if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):
    inference_server.serve()
else:
    inference_server.run_local_gateway(
        (
            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',
            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',
        )
    )
